{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bfa0928",
   "metadata": {},
   "source": [
    "# **Introduction to Model Context Protocol(MCP)**\n",
    "\n",
    "## **Imprtance of MCP**\n",
    "\n",
    "The AI ecosystem is evolving rapidly, with Large Language Models (LLMs) and other AI systems becoming increasingly capable. However, these models are often limited by their training data and lack access to real-time information or specialized tools. This limitation hinders the potential of AI systems to provide truly relevant, accurate, and helpful responses in many scenarios.\n",
    "\n",
    "This is where Model Context Protocol (MCP) comes in. MCP enables AI models to connect with external data sources, tools, and environments, allowing for the seamless transfer of information and capabilities between AI systems and the broader digital world. This interoperability is crucial for the growth and adoption of truly useful AI applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde39d8e",
   "metadata": {},
   "source": [
    "## **Key Concepts and Terminology**\n",
    "\n",
    "MCP is often described as the “USB-C for AI applications.” Just as USB-C provides a standerdized physical and logical interface for connectinng various peripherals to computing devices, MCP offers a consistent protocol for linking AI models to external capabilities. This standardization benefits the entire ecosystem:\n",
    "\n",
    "- **users** enjoy simpler and more consistent experiences across AI applications\n",
    "- **AI application developers** gain easy integration with a growing ecosystem of tools and data sources\n",
    "- **tool and data providers** need only create a single implementation that works with multiple AI applications. \n",
    "- the border ecosystem benefits from incresed interoperability, innovation, and reduced fragmentation\n",
    "\n",
    "### **The Integration Problem**\n",
    "\n",
    "The **M×N Integration** Problem refers to the challenge of connecting M different AI applications to N different external tools or data sources without a standardized approach.\n",
    "\n",
    "### **Without MCP (M×N Problem)**\n",
    "\n",
    "Without a protocol like MCP, developers would need to create M×N custom integrations—one for each possible pairing of an AI application with an external capability.\n",
    "\n",
    "![](https://huggingface.co/datasets/mcp-course/images/resolve/main/unit1/1.png)\n",
    "\n",
    "Each AI application would need to integrate with each tool/data source individually. This is a very complex and expensive process which introduces a lot of friction for developers, and high maintenance costs.\n",
    "\n",
    "Once we have multiple models and multiple tools, the number of integrations becomes too large to manage, each with its own unique interface.\n",
    "\n",
    "![](https://huggingface.co/datasets/mcp-course/images/resolve/main/unit1/1a.png)\n",
    "\n",
    "### **With MCP (M+N Solution)**\n",
    "\n",
    "MCP transforms this into an M+N problem by providing a standard interface: each AI application implements the client side of MCP once, and each tool/data source implements the server side once. This dramatically reduces integration complexity and maintenance burden.\n",
    "\n",
    "![](https://huggingface.co/datasets/mcp-course/images/resolve/main/unit1/2.png)\n",
    "\n",
    "Each AI application implements the client side of MCP once, and each tool/data source implements the server side once.\n",
    "\n",
    "### **Core MCP Terminology**\n",
    "\n",
    "Now that we understand the problem that MCP solves, let’s dive into the core terminology and concepts that make up the MCP protocol.\n",
    "\n",
    "```\n",
    "MCP is a standard like HTTP or USB-C, and is a protocol for connecting AI applications to external tools and data sources. Therefore, using standard terminology is crucial to making the MCP work effectively.\n",
    "\n",
    "When documenting our applications and communicating with the community, we should use the following terminology.\n",
    "```\n",
    "\n",
    "### **Components**\n",
    "\n",
    "Just like client server relationshios in HTTP, MCP has a client and a server.\n",
    "\n",
    "![](https://huggingface.co/datasets/mcp-course/images/resolve/main/unit1/3.png)\n",
    "\n",
    "- **Host**: The user-facing AI application that end-users interact with directly. Examples include Anthropic’s Claude Desktop, AI-enhanced IDEs like Cursor, inference libraries like Hugging Face Python SDK, or custom applications built in libraries like LangChain or smolagents. Hosts initiate connections to MCP Servers and orchestrate the overall flow between user requests, LLM processing, and external tools.\n",
    "\n",
    "- **Client**: A component within the host application that manages communication with a specific MCP Server. Each Client maintains a 1:1 connection with a single Server, handling the protocol-level details of MCP communication and acting as an intermediary between the Host’s logic and the external Server.\n",
    "\n",
    "- **Server**: An external program or service that exposes capabilities (Tools, Resources, Prompts) via the MCP protocol.\n",
    "\n",
    "```\n",
    "A lot of content uses ‘Client’ and ‘Host’ interchangeably. Technically speaking, the host is the user-facing application, and the client is the component within the host application that manages communication with a specific MCP Server.\n",
    "```\n",
    "\n",
    "### **Capabilities**\n",
    "\n",
    "Of course, your application’s value is the sum of the capabilities it offers. So the capabilities are the most important part of your application. MCP’s can connect with any software service, but there are some common capabilities that are used for many AI applications.\n",
    "\n",
    "| **Capability** | **Description** | **Example** |\n",
    "| ---- | ---- |---- |\n",
    "| **Tools** | Executable functions that the AI model can invoke to perform actions or retrieve computed data. Typically relating to the use case of the application. | A tool for a weather application might be a function that returns the weather in a specific location.| \n",
    "| **Resources** | Read-only data sources that provide context without significant computation. | A researcher assistant might have a resource for scientific papers. |\n",
    "| **Prompts** | Pre-defined templates or workflows that guide interactions between users, AI models, and the available capabilities. | A summarization prompt. |\n",
    "| **Sampling** | Server-initiated requests for the Client/Host to perform LLM interactions, enabling recursive actions where the LLM can review generated content and make further decisions. | A writing application reviewing its own output and decides to refine it further. | \n",
    "\n",
    "In the following diagram, we can see the collective capabilities applied to a use case for a code agent. \n",
    "\n",
    "![](https://huggingface.co/datasets/mcp-course/images/resolve/main/unit1/8.png)\n",
    "\n",
    "This application might use their MCP entities in the following way: \n",
    "\n",
    "| **Entity** | **Name** | **Description** | \n",
    "| Tool | Code Interpreter | A tool that can execute code that the LLM writes. |\n",
    "| Resource | Documentation | A resource that contains the documentation of the application. | \n",
    "| Prompt | Code Style | A prompt that guides the LLM to generate code. |\n",
    "| Sampling | Code Review | A sampling that allows the LLM to review the code and make further decisions. | \n",
    "\n",
    "### **Conclusion**\n",
    "\n",
    "Understanding these key concepts and terminology provides the foundation for working with MCP effectively. In the following sections, we’ll build on this foundation to explore the architectural components, communication protocol, and capabilities that make up the Model Context Protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f569747e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1693a087",
   "metadata": {},
   "source": [
    "## **Architectural Components of MCP**\n",
    "\n",
    "Let’s dive deeper into the architectural components that make up the MCP ecosystem.\n",
    "\n",
    "### **Host, Client, and server**\n",
    "\n",
    "The Model Context Protocol (MCP) is built on a client-server architecture that enables structured communication between AI models and external systems.\n",
    "\n",
    "![](https://huggingface.co/datasets/mcp-course/images/resolve/main/unit1/4.png)\n",
    "\n",
    "The MCP architecture consists of three primary components, each with well-defined roles and responsibilities: Host, Client, and Server. We touched on these in the previous section, but let’s dive deeper into each component and their responsibilities.\n",
    "\n",
    "**Host**\n",
    "\n",
    "The **Host** is the user-facing AI application that end-users interact with directly.\n",
    "\n",
    "Examples include: \n",
    "\n",
    "- AI Chat apps like OpenAI ChatGPT or Anthropic’s Claude Desktop\n",
    "- AI-enhanced IDEs like Cursor, or integrations to tools like Continue.dev\n",
    "- AI-enhanced IDEs like Cursor, or integrations to tools like Continue.dev\n",
    "\n",
    "The Host's reponsibilities include: \n",
    "\n",
    "- Managing user interactions and permissions\n",
    "- Initiating connections to MCP Servers via MCP Clients\n",
    "- Orchestrating the overall flow between user requests, LLM processing, and external tools\n",
    "- Rendering results back to users in a coherent format\n",
    "\n",
    "In most cases, users will select their host application based on their needs and preferences. For example, a developer may choose Cursor for its powerful code editing capabilities, while domain experts may use custom applications built in smolagents.\n",
    "\n",
    "**Client**\n",
    "\n",
    "The **Client** is a component within the Host application that manages communication with a specific MCP Server. Key characteristics include:\n",
    "\n",
    "- Each Client maintains a 1:1 connection with a single Server\n",
    "- Handles the protocol-level details of MCP communication\n",
    "- Acts as the intermediary between the Host’s logic and the external Server\n",
    "\n",
    "**Server**\n",
    "\n",
    "The **Server** is an external program or service that exposes capabilities to AI models via the MCP protocol. Servers:\n",
    "\n",
    "- Provide access to specific external tools, data sources, or services\n",
    "- Act as lightweight wrappers around existing functionality\n",
    "- Can run locally (on the same machine as the Host) or remotely (over a network)\n",
    "- Expose their capabilities in a standardized format that Clients can discover and use\n",
    "\n",
    "**Communication Flow**\n",
    "\n",
    "Let’s examine how these components interact in a typical MCP workflow:\n",
    "\n",
    "1. **User Interaction**: The user interacts with the **Host** application, expressing an intent or query.\n",
    "\n",
    "1. **Host Processing**: The **Host** processes the user’s input, potentially using an LLM to understand the request and determine which external capabilities might be needed.\n",
    "\n",
    "1. **Client Connection**: The **Host** directs its **Client** component to connect to the appropriate Server(s).\n",
    "\n",
    "1. **Capability Discovery**: The **Client** queries the **Server** to discover what capabilities (Tools, Resources, Prompts) it offers.\n",
    "\n",
    "1. **Capability Invocation**: Based on the user’s needs or the LLM’s determination, the Host instructs the **Client** to invoke specific capabilities from the **Server**.\n",
    "\n",
    "1. **Server Execution**: The **Server** executes the requested functionality and returns results to the **Client**.\n",
    "\n",
    "1. **Result Integration**: The **Client** relays these results back to the Host, which incorporates them into the context for the LLM or presents them directly to the user.\n",
    "\n",
    "A key advantage of this architecture is its modularity. A single **Host** can connect to multiple **Servers** simultaneously via different **Clients**. New **Servers** can be added to the ecosystem without requiring changes to existing **Hosts**. Capabilities can be easily composed across different **Servers**.\n",
    "\n",
    "The architecture might appear simple, but its power lies in the standardization of the communication protocol and the clear separation of responsibilities between components. This design allows for a cohesive ecosystem where AI models can seamlessly connect with an ever-growing array of external tools and data sources.\n",
    "\n",
    "## **Conclusion**\n",
    "\n",
    "These interaction patterns are guided by several key principles that shape the design and evolution of MCP. The protocol emphasizes standardization by providing a universal protocol for AI connectivity, while maintaining simplicity by keeping the core protocol straightforward yet enabling advanced features. Safety is prioritized by requiring explicit user approval for sensitive operations, and discoverability enables dynamic discovery of capabilities. The protocol is built with extensibility in mind, supporting evolution through versioning and capability negotiation, and ensures interoperability across different implementations and environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206cb768",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcef8a5a",
   "metadata": {},
   "source": [
    "## **The Communication Protocol**\n",
    "\n",
    "MCP defines a standerdized communication protocol that enables Clients and Servers to exchange messages in a consistent, predictable way. This standardization is critical for interoperability across the community. In this section, we’ll explore the protocol structure and transport mechanisms used in MCP.\n",
    "\n",
    "### **JSON-RPC: The Foundation**\n",
    "\n",
    "At its core, MCP uses **JSON-RPC 2.0** as the message format for all communication between Clients and Servers. JSON-RPC is a lightweight remote procedure call protocol encoded in JSON, which makes it:\n",
    "\n",
    "- Human-readable and easy to debug\n",
    "- Language-agnostic, supporting implementation in any programming environment\n",
    "- Well-established, with clear specifications and widespread adoption\n",
    "\n",
    "![](https://huggingface.co/datasets/mcp-course/images/resolve/main/unit1/5.png)\n",
    "\n",
    "The protocol defines three types of messages:\n",
    "\n",
    "**1. Requests**\n",
    "\n",
    "Sent from **Client** to **Server** to initiate an operation. A Request message includes:\n",
    "\n",
    "- A unique identifier (id)\n",
    "- The method name to invoke (e.g., `tools/call`)\n",
    "- Parameters for the method(if any)\n",
    "\n",
    "Example Request: \n",
    "\n",
    "```python\n",
    "{\n",
    "  \"jsonrpc\": \"2.0\",\n",
    "  \"id\": 1,\n",
    "  \"method\": \"tools/call\",\n",
    "  \"params\": {\n",
    "    \"name\": \"weather\",\n",
    "    \"arguments\": {\n",
    "      \"location\": \"San Francisco\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**2. Responses**\n",
    "\n",
    "Sent from server to Client in reply ro Request. A Response message includes:\n",
    "\n",
    "- The same `id` as the correspinding Request\n",
    "- Either a `result` (for success) or an `error` (for failure)\n",
    "\n",
    "Example Success Response: \n",
    "```Python\n",
    "{\n",
    "  \"jsonrpc\": \"2.0\",\n",
    "  \"id\": 1,\n",
    "  \"result\": {\n",
    "    \"temperature\": 62,\n",
    "    \"conditions\": \"Partly cloudy\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "Example Error Response:\n",
    "\n",
    "```Python\n",
    "{\n",
    "  \"jsonrpc\": \"2.0\",\n",
    "  \"id\": 1,\n",
    "  \"error\": {\n",
    "    \"code\": -32602,\n",
    "    \"message\": \"Invalid location parameter\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**3. Notifications**\n",
    "\n",
    "One-way messages that don’t require a response. Typically sent from Server to Client to provide updates or notifications about events.\n",
    "\n",
    "Example Notification:\n",
    "\n",
    "```python \n",
    "{\n",
    "  \"jsonrpc\": \"2.0\",\n",
    "  \"method\": \"progress\",\n",
    "  \"params\": {\n",
    "    \"message\": \"Processing data...\",\n",
    "    \"percent\": 50\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "### **Transport Mechanisms**\n",
    "\n",
    "JSON-RPC defines the message format, but MCP also specifies how messages are transpoted between Clients and Servers. Two primary transport mechanisms are supported. \n",
    "\n",
    "**stdio (Standard Input/Output)**\n",
    "\n",
    "The stdio transport is used for local communication, where the Client and Server run on the same machine:\n",
    "\n",
    "The Host application launches the Server as a subprocess and communicates with it by writing to its standard input (stdin) and reading from its standard output (stdout).\n",
    "\n",
    "**`Use cases`** for this transport are local tools like file system access or running local scripts.\n",
    "\n",
    "The main **Advantages** of this transport are that it’s simple, no network configuration required, and securely sandboxed by the operating system.\n",
    "\n",
    "**HTTP + SSE (Server-Sent Events) / Streamable HTTP**\n",
    "\n",
    "The HTTP+SSE transport is used for remote communication, where the Client and Server might be on different machines:\n",
    "\n",
    "Communication happens over HTTP, with the Server using Server-Sent Events (SSE) to push updates to the Client over a persistent connection.\n",
    "\n",
    "**`Use cases`** for this transport are connecting to remote APIs, cloud services, or shared resources.\n",
    "\n",
    "The main **Advantages** of this transport are that it works across networks, enables integration with web services, and is compatible with serverless environments.\n",
    "\n",
    "Recent updates to the MCP standard have introduced or refined “Streamable HTTP,” which offers more flexibility by allowing servers to dynamically upgrade to SSE for streaming when needed, while maintaining compatibility with serverless environments.\n",
    "\n",
    "Recent updates to the MCP standard have introduced or refined “Streamable HTTP,” which offers more flexibility by allowing servers to dynamically upgrade to SSE for streaming when needed, while maintaining compatibility with serverless environments.\n",
    "\n",
    "### **The Interaction Lifecycle**\n",
    "\n",
    "In the previous section, we discussed the lifecycle of a single interaction between a Client (💻) and a Server (🌐). Let’s now look at the lifecycle of a complete interaction between a Client and a Server in the context of the MCP protocol.\n",
    "\n",
    "The MCP protocol defines a structured interaction lifecycle between Clients and Servers:\n",
    "\n",
    "**Initialization**\n",
    "\n",
    "The Client connects to the Server and they exchange protocol versions and capabilities, and the Server responds with its supported protocol version and capabilities.\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td style=\"background-color: lightgreen; text-align: center; padding: 10px; border: 1px solid #ccc; border-radius: 4px;\">💻</td>\n",
    "    <td style=\"text-align: center;\">→<br>initialize</td>\n",
    "    <td style=\"background-color: lightblue; text-align: center; padding: 10px; border: 1px solid #ccc; border-radius: 4px;\">🌐</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"background-color: lightgreen; text-align: center; padding: 10px; border: 1px solid #ccc; border-radius: 4px;\">💻</td>\n",
    "    <td style=\"text-align: center;\">←<br>response</td>\n",
    "    <td style=\"background-color: lightblue; text-align: center; padding: 10px; border: 1px solid #ccc; border-radius: 4px;\">🌐</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"background-color: lightgreen; text-align: center; padding: 10px; border: 1px solid #ccc; border-radius: 4px;\">💻</td>\n",
    "    <td style=\"text-align: center;\">→<br>initialize</td>\n",
    "    <td style=\"background-color: lightblue; text-align: center; padding: 10px; border: 1px solid #ccc; border-radius: 4px;\">🌐</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "The Client confirms the initialization is complete via a notification message.\n",
    "\n",
    "**Discovery**\n",
    "\n",
    "The Client requests information about available capabilities and the Server responds with a list of available tools.\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td style=\"background-color: lightgreen; text-align: center; padding: 10px; border: 1px solid #ccc; border-radius: 4px;\">💻</td>\n",
    "    <td style=\"text-align: center;\">→<br>tools/list</td>\n",
    "    <td style=\"background-color: lightblue; text-align: center; padding: 10px; border: 1px solid #ccc; border-radius: 4px;\">🌐</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"background-color: lightgreen; text-align: center; padding: 10px; border: 1px solid #ccc; border-radius: 4px;\">💻</td>\n",
    "    <td style=\"text-align: center;\">←<br>response</td>\n",
    "    <td style=\"background-color: lightblue; text-align: center; padding: 10px; border: 1px solid #ccc; border-radius: 4px;\">🌐</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "This process coukd be repeated for each tool, resource, or prompt type. \n",
    "\n",
    "**Execution**\n",
    "\n",
    "The Client invokes capabilities based on the Host's needs. \n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td style=\"background-color: lightgreen; text-align: center; padding: 10px; border: 1px solid #ccc; border-radius: 4px;\">💻</td>\n",
    "    <td style=\"text-align: center;\">→<br>tools/call</td>\n",
    "    <td style=\"background-color: lightblue; text-align: center; padding: 10px; border: 1px solid #ccc; border-radius: 4px;\">🌐</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"background-color: lightgreen; text-align: center; padding: 10px; border: 1px solid #ccc; border-radius: 4px;\">💻</td>\n",
    "    <td style=\"text-align: center;\">←<br>notification (optional progress)</td>\n",
    "    <td style=\"background-color: lightblue; text-align: center; padding: 10px; border: 1px solid #ccc; border-radius: 4px;\">🌐</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"background-color: lightgreen; text-align: center; padding: 10px; border: 1px solid #ccc; border-radius: 4px;\">💻</td>\n",
    "    <td style=\"text-align: center;\">←<br>response</td>\n",
    "    <td style=\"background-color: lightblue; text-align: center; padding: 10px; border: 1px solid #ccc; border-radius: 4px;\">🌐</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "**Termination**\n",
    "\n",
    "The connection is gracefully closed when no longer needed and the Server acknowledges the shutdown request. \n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td style=\"background-color: lightgreen; text-align: center; padding: 10px; border: 1px solid #ccc; border-radius: 4px;\">💻</td>\n",
    "    <td style=\"text-align: center;\">→<br>shutdown</td>\n",
    "    <td style=\"background-color: lightblue; text-align: center; padding: 10px; border: 1px solid #ccc; border-radius: 4px;\">🌐</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"background-color: lightgreen; text-align: center; padding: 10px; border: 1px solid #ccc; border-radius: 4px;\">💻</td>\n",
    "    <td style=\"text-align: center;\">←<br>response</td>\n",
    "    <td style=\"background-color: lightblue; text-align: center; padding: 10px; border: 1px solid #ccc; border-radius: 4px;\">🌐</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"background-color: lightgreen; text-align: center; padding: 10px; border: 1px solid #ccc; border-radius: 4px;\">💻</td>\n",
    "    <td style=\"text-align: center;\">→<br>exit</td>\n",
    "    <td style=\"background-color: lightblue; text-align: center; padding: 10px; border: 1px solid #ccc; border-radius: 4px;\">🌐</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "The Client sends the final exit message to complete the termination.\n",
    "\n",
    "**Protocol Evolution**\n",
    "\n",
    "The MCP protocol is designed to be extensible and adaptable. The initialization phase includes version negotiation, allowing for backward compatibility as the protocol evolves. Additionally, capability discovery enables Clients to adapt to the specific features each Server offers, enabling a mix of basic and advanced Servers in the same ecosystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5688977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab331a83",
   "metadata": {},
   "source": [
    "## Understanding MCP Capabilities**\n",
    "\n",
    "MCP Servers expose a variety of capabilities to Clients through the communication protocol. These capabilities fall into four main categories, each with distinct characteristics and use cases. Let’s explore these core primitives that form the foundation of MCP’s functionality.\n",
    "\n",
    "### **Tools**\n",
    "\n",
    "Tools are executable functions or actions that the AI model can invoke through the MCP protocol.\n",
    "\n",
    "- **Control**: Tools are typically **model-controlled**, meaning that the AI model (LLM) decides when to call them based on the user’s request and context.\n",
    "\n",
    "- **Safety**: Due to their ability to perform actions with side effects, tool execution can be dangerous. Therefore, they typically require explicit user approval.\n",
    "\n",
    "- **Use Cases**: Sending messages, creating tickets, querying APIs, performing calculations.\n",
    "\n",
    "**Example**: A weather tool that fetches current weather data for a given location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71024b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(location: str) -> dict:\n",
    "    \"\"\"Get the current weather for a specified location.\"\"\"\n",
    "    return {\n",
    "        \"temperature\" : 72,\n",
    "        \"condition\" : \"Sunny\",\n",
    "        \"humidity\" : 45,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307701c5",
   "metadata": {},
   "source": [
    "### **Resources**\n",
    "\n",
    "Resources provide read-only access to data sources, allowing the AI model to retrieve context without executing complex logic.\n",
    "\n",
    "- **Control**: Resources are **application-controlled**, meaning the Host application typically decides when to access them.\n",
    "- **Nature**: They are designed for data retrieval with minimal computation, similar to GET endpoints in REST APIs.\n",
    "- **Safety**: Since they are read-only, they typically present lower security risks than Tools.\n",
    "- **Use** Cases: Accessing file contents, retrieving database records, reading configuration information.\n",
    "\n",
    "**Example**: A resource that provides access to file contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ac911bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path: str) -> str:\n",
    "    \"\"\"Read the contents of a file at the specified path.\"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23a268d",
   "metadata": {},
   "source": [
    "### **Prompts**\n",
    "\n",
    "Prompts are predefined templates or workflows that guide the interaction between the user, the AI model, and the Server’s capabilities.\n",
    "\n",
    "- **Control**: Prompts are **user-controlled**, often presented as options in the Host application’s UI.\n",
    "- **Purpose**: They structure interactions for optimal use of available Tools and Resources.\n",
    "- **Selection**: Users typically select a prompt before the AI model begins processing, setting context for the interaction.\n",
    "- **Use Cases**: Common workflows, specialized task templates, guided interactions.\n",
    "\n",
    "**Example**: A prompt template for generating a code review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b680beb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_review(code: str, language: str) -> list:\n",
    "    \"\"\"Generate a code review for the provided code snippet.\"\"\"\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"You are a code reviewer examining {language} code. Provide a detailed review highlighting best practices, potential issues, and suggestions for improvement.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Please review this {language} code:\\n\\n```{language}\\n{code}\\n```\"\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8df69e2",
   "metadata": {},
   "source": [
    "### **Sampling**\n",
    "\n",
    "Sampling allows Servers to request the Client (specifically, the Host application) to perform LLM interactions. \n",
    "\n",
    "- **Control**: Sampling is **server-initiated** but requires Client/Host facilitation.\n",
    "- **Purpose**: It enables server-driven agentic behaviors and potentially recursive or multi-step interactions.\n",
    "- **Safety**: Like Tools, sampling operations typically require user approval.\n",
    "- **Use Cases**: Complex multi-step tasks, autonomous agent workflows, interactive processes.\n",
    "\n",
    "**Example**: A Server might request the Client to analyze data it has processed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f847c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_sampling(messages, system_prompt = None, include_context = \"none\"):\n",
    "    \"\"\"Request LLM sampling from the client.\"\"\"\n",
    "    # In a real implementation, this would send a request to the client\n",
    "    return {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Analysis of the provided data...\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4029de",
   "metadata": {},
   "source": [
    "The sampling flow follows these steps:\n",
    "\n",
    "1. Server sends a `sampling/createMessage` request to the client\n",
    "1. Client reviews the request and can modify it\n",
    "1. Client samples from an LLM\n",
    "1. Client reviews the completion\n",
    "1. Client returns the result to the server\n",
    "\n",
    "### **How Capabilities Work Together**\n",
    "\n",
    "Let’s look at how these capabilities work together to enable complex interactions. In the table below, we’ve outlined the capabilities, who controls them, the direction of control, and some other details.\n",
    "\n",
    "| Capability | Controlled By | Direction | Side Effects | Approval Needed |Typical Use Cases |\n",
    "| ---- | ---- | ---- | ---- | ---- | ---- |\n",
    "| Tools | Model (LLM) | Client → Server | Yes (potentially) | Yes\t| Actions, API calls, data manipulation |\n",
    "| Resources | Application | Client → Server | No (read-only) | Typically no | Data retrieval, context gathering |\n",
    "| Prompts | User | Server → Client | No | No (selected by user) | Guided workflows, specialized templates | \n",
    "| Sampling | Server\t| Server → Client → Server | Indirectly | Yes |\tMulti-step tasks, agentic behaviors |\n",
    "\n",
    "\n",
    "These capabilities are designed to work together in complementary ways:\n",
    "\n",
    "1. A user might select a **Prompt** to start a specialized workflow\n",
    "1. The Prompt might include context from **Resources**\n",
    "1. During processing, the AI model might call **Tools** to perform specific actions\n",
    "1. For complex operations, the Server might use **Sampling** to request additional LLM processing\n",
    "\n",
    "The distinction between these primitives provides a clear structure for MCP interactions, enabling AI models to access information, perform actions, and engage in complex workflows while maintaining appropriate control boundaries.\n",
    "\n",
    "### **Discovery Process**\n",
    "\n",
    "One of MCP’s key features is dynamic capability discovery. When a Client connects to a Server, it can query the available Tools, Resources, and Prompts through specific list methods:\n",
    "\n",
    "- `tools/list`: Discover available Tools\n",
    "- `resources/list`: Discover available Resources\n",
    "- `prompts/list`: Discover available Prompts\n",
    "\n",
    "This dynamic discovery mechanism allows Clients to adapt to the specific capabilities each Server offers without requiring hardcoded knowledge of the Server’s functionality.\n",
    "\n",
    "### **Conclusion**\n",
    "\n",
    "Understanding these core primitives is essential for working with MCP effectively. By providing distinct types of capabilities with clear control boundaries, MCP enables powerful interactions between AI models and external systems while maintaining appropriate safety and control mechanisms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccd2bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d5f321e",
   "metadata": {},
   "source": [
    "## **MCP SDK**\n",
    "\n",
    "The Model Context Protocol provides official SDKs for both JavaScript, Python and other languages. This makes it easy to implement MCP clients and servers in your applications. These SDKs handle the low-level protocol details, allowing you to focus on building your application’s capabilities.\n",
    "\n",
    "**SDK Overview**\n",
    "\n",
    "Both SDKs provide similar core functionality, following the MCP protocol specification we discussed earlier. They handle:\n",
    "\n",
    "- Protocol-level communication\n",
    "- Capability registration and discovery\n",
    "- Message serialization/deserialization \n",
    "- Connection mmanagement\n",
    "- Error handling\n",
    "\n",
    "**Core Primitives Implementation**\n",
    "\n",
    "Let’s explore how to implement each of the core primitives (Tools, Resources, and Prompts) using both SDKs.\n",
    "\n",
    "### **Next Steps**\n",
    "\n",
    "We’ve only scratched the surface of what you can do with the MCP but you’ve already got a basic server running. In fact, you’ve also connected to it using the MCP Client in the browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b2aa4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d45adbf",
   "metadata": {},
   "source": [
    "## **MCP Clients**\n",
    "\n",
    "Now that we have a basic understanding of the MCP, we can explore the essential role of MCP Clients in the Model Context Protocol ecosystem. \n",
    "\n",
    "In this part of Unit 1, we’ll explore the essential role of MCP Clients in the Model Context Protocol ecosystem.\n",
    "\n",
    "In this section, we will:\n",
    "\n",
    "- Understand what MCP Clients are and their role in the MCP architecture\n",
    "- Learn about the key responsibilities of MCP Clients\n",
    "- Explore the major MCP Client implementations\n",
    "- Discover how to use Hugging Face’s MCP Client implementation\n",
    "- See practical examples of MCP Client usage\n",
    "\n",
    "### **Understanding MCP Clients**\n",
    "\n",
    "MCP Clients are crucial components that act as the bridge between AI applications (Hosts) and external capabilities provided by MCP Servers. Think of the Host as your main application (like an AI assistant or IDE) and the Client as a specialized module within that Host responsible for handling MCP communications.\n",
    "\n",
    "### **User Interface Client**\n",
    "\n",
    "Let’s start by exploring the user interface clients that are available for the MCP.\n",
    "\n",
    "**Chat Interface Clients**\n",
    "\n",
    "Anthropic’s Claude Desktop stands as one of the most prominent MCP Clients, providing integration with various MCP Servers.\n",
    "\n",
    "**Interactive Development Clients**\n",
    "\n",
    "Cursor’s MCP Client implementation enables AI-powered coding assistance through direct integration with code editing capabilities. It supports multiple MCP Server connections and provides real-time tool invocation during coding, making it a powerful tool for developers.\n",
    "\n",
    "Continue.dev is another example of an interactive development client that supports MCP and connects to an MCP server from VS Code.\n",
    "\n",
    "**Configuring MCP Clients**\n",
    "\n",
    "Now that we’ve covered the core of the MCP protocol, let’s look at how to configure your MCP servers and clients.\n",
    "\n",
    "Effective deployment of MCP servers and clients requires proper configuration.\n",
    "\n",
    "**MCP Configuration Files**\n",
    "\n",
    "MCP hosts use configuration files to manage server connections. These files define which servers are available and how to connect to them.\n",
    "\n",
    "Fortunately, the configuration files are very simple, easy to understand, and consistent across major MCP hosts.\n",
    "\n",
    "### **mcp.json Structure**\n",
    "\n",
    "The standard configuration file for MCP is named mcp.json. Here’s the basic structure:\n",
    "\n",
    "This is the basic structure of the mcp.json can be passed to applications like Claude Desktop, Cursor, or VS Code.\n",
    "\n",
    "```python\n",
    "{\n",
    "  \"servers\": [\n",
    "    {\n",
    "      \"name\": \"Server Name\",\n",
    "      \"transport\": {\n",
    "        \"type\": \"stdio|sse\",\n",
    "        // Transport-specific configuration\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "In this example, we have a single server with a name and a transport type. The transport type is either `stdio or sse`.\n",
    "\n",
    "### **Configuration for stdio Transport**\n",
    "\n",
    "For local servers using stdio transport, the configuration includes the command and arguments to launch the server process:\n",
    "\n",
    "```python\n",
    "{\n",
    "  \"servers\": [\n",
    "    {\n",
    "      \"name\": \"File Explorer\",\n",
    "      \"transport\": {\n",
    "        \"type\": \"stdio\",\n",
    "        \"command\": \"python\",\n",
    "        \"args\": [\"/path/to/file_explorer_server.py\"] // This is an example, we'll use a real server in the next unit\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "Here, we have a server called “File Explorer” that is a local script.\n",
    "\n",
    "\n",
    "### **Configuration for HTTP+SSE Transport**\n",
    "\n",
    "For remote servers using HTTP+SSE transport, the configuration includes the server URL:\n",
    "\n",
    "```python\n",
    "{\n",
    "  \"servers\": [\n",
    "    {\n",
    "      \"name\": \"Remote API Server\",\n",
    "      \"transport\": {\n",
    "        \"type\": \"sse\",\n",
    "        \"url\": \"https://example.com/mcp-server\"\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "### Environment Variables in Configuration\n",
    "\n",
    "Environment variables can be passed to server processes using the env field. Here’s how to access them in your server code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3eac3edd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "GITHUB_TOKEN environment variable is required",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m github_token = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mGITHUB_TOKEN\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m github_token:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mGITHUB_TOKEN environment variable is required\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmake_github_request\u001b[39m():\n\u001b[32m      9\u001b[39m     headers = {\u001b[33m\"\u001b[39m\u001b[33mAuthorization\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBearer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgithub_token\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m}\n",
      "\u001b[31mValueError\u001b[39m: GITHUB_TOKEN environment variable is required"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "github_token = os.environ.get(\"GITHUB_TOKEN\")\n",
    "\n",
    "if not github_token:\n",
    "    raise ValueError(\"GITHUB_TOKEN environment variable is required\")\n",
    "\n",
    "def make_github_request():\n",
    "    headers = {\"Authorization\": f\"Bearer {github_token}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122b951e",
   "metadata": {},
   "source": [
    "The corresponding configuration in `mcp.json` would look like this:\n",
    "\n",
    "```python\n",
    "{\n",
    "  \"servers\": [\n",
    "    {\n",
    "      \"name\": \"GitHub API\",\n",
    "      \"transport\": {\n",
    "        \"type\": \"stdio\",\n",
    "        \"command\": \"python\",\n",
    "        \"args\": [\"/path/to/github_server.py\"], // This is an example, we'll use a real server in the next unit\n",
    "        \"env\": {\n",
    "          \"GITHUB_TOKEN\": \"your_github_token\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "### **Configuration Examples**\n",
    "\n",
    "Let’s look at some real-world configuration scenarios:\n",
    "\n",
    "### **Scenario 1: Local Server Configuration**\n",
    "\n",
    "In this scenario, we have a local server that is a Python script which could be a file explorer or a code editor.\n",
    "\n",
    "```python \n",
    "{\n",
    "  \"servers\": [\n",
    "    {\n",
    "      \"name\": \"File Explorer\",\n",
    "      \"transport\": {\n",
    "        \"type\": \"stdio\",\n",
    "        \"command\": \"python\",\n",
    "        \"args\": [\"/path/to/file_explorer_server.py\"] // This is an example, we'll use a real server in the next unit\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "### **Scenario 2: Remote Server Configuration**\n",
    "\n",
    "In this scenario, we have a remote server that is a weather API.\n",
    "\n",
    "```python\n",
    "{\n",
    "  \"servers\": [\n",
    "    {\n",
    "      \"name\": \"Weather API\",\n",
    "      \"transport\": {\n",
    "        \"type\": \"sse\",\n",
    "        \"url\": \"https://example.com/mcp-server\" // This is an example, we'll use a real server in the next unit\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "Proper configuration is essential for successfully deploying MCP integrations. By understanding these aspects, you can create robust and reliable connections between AI applications and external capabilities.\n",
    "\n",
    "In the next section, we’ll explore the ecosystem of MCP servers available on Hugging Face Hub and how to publish your own servers there.\n",
    "\n",
    "\n",
    "### **Tiny Agents Clients**\n",
    "\n",
    "Now, let’s explore how to use `MCP Clients` within code.\n",
    "\n",
    "You can also use tiny agents as MCP Clients to connect directly to MCP servers from your code. Tiny agents provide a simple way to create AI agents that can use tools from MCP servers.\n",
    "\n",
    "Tiny Agent can run MCP servers with a command line environment. To do this, we will need to install `npm` and run the server with `npx`. **We’ll need these for both Python and JavaScript**.\n",
    "\n",
    "Let’s install npx with npm. If you don’t have npm installed, check out the npm documentation.\n",
    "\n",
    "### **Setup**\n",
    "\n",
    "First, we will need to install `npx` if you don’t have it installed. You can do this with the following command:\n",
    "\n",
    "```python\n",
    "# install npx\n",
    "npm install -g npx\n",
    "```\n",
    "\n",
    "Then, we will need to install the huggingface_hub package with the MCP support. This will allow us to run MCP servers and clients.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a7ba0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c04eef8b",
   "metadata": {},
   "source": [
    "## **Gradio MCP Intefration**\n",
    "\n",
    "We’ve now explored the core concepts of the MCP protocol and how to implement MCP Servers and Clients. In this section, we’re going to make things slightly easier by using Gradio to create an MCP Server!\n",
    "\n",
    "### **Introduction to Gradio**\n",
    "\n",
    "Gradio allows developers to create UIs for their models with just a few lines of Python code. It’s particularly useful for:\n",
    "\n",
    "- Creating demos and prototypes\n",
    "- Sharing models with non-technical users\n",
    "- Testing and debugging model behavior\n",
    "\n",
    "With the addition of MCP support, Gradio now offers a straightforward way to expose AI model capabilities through the standardized MCP protocol.\n",
    "\n",
    "Combining Gradio with MCP allows you to create both human-friendly interfaces and AI-accessible tools with minimal code. But best of all, Gradio is already well-used by the AI community, so you can use it to share your MCP Servers with others.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c11da4",
   "metadata": {},
   "source": [
    "### **Prerequisites**\n",
    "\n",
    "To use Gradio with MCP support, you’ll need to install Gradio with the MCP extra:\n",
    "```python\n",
    "pip install \"gradio[mcp]\"\n",
    "```\n",
    "\n",
    "### **How It Works Behind the Scenes**\n",
    "\n",
    "When you set `mcp_server=True` in `launch()`, several things happen:\n",
    "\n",
    "1. Gradio functions are automatically converted to MCP Tools\n",
    "1. Input components map to tool argument schemas\n",
    "1. Output components determine the response format\n",
    "1. The Gradio server now also listens for MCP protocol messages\n",
    "1. JSON-RPC over HTTP+SSE is set up for client-server communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc549d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df728620",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcp_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
